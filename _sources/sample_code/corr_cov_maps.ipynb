{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation & Covariance Maps\n",
    "\n",
    "This module calculates the correlation & covariance between indices time series and anomaly time series, variance and mean height, at each longitude/latitude grid point. Methods used are both Pearson and Spearman rank.\n",
    "\n",
    "Call made to class that creates and saves figures based on correlation and covariance matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from load_indices import Indices\n",
    "from create_maps import CreateMaps\n",
    "\n",
    "\n",
    "class CorrCovMaps(): \n",
    "    \"\"\" \n",
    "    Attributes\n",
    "    ----------\n",
    "    self._path: str\n",
    "        Root directory.\n",
    "    self._anoms: xarray.Dataset\n",
    "        Dataset containing time series for all lat/lon grid points.\n",
    "    self._index_dict: dict\n",
    "        Dictionary containing arrays of all normalised indices' time series.\n",
    "    self._corr_arrays: numpy.ndarray\n",
    "        Array to store correlation values between index and all lat/lon \n",
    "        grid points.\n",
    "    self._cov_arrays: numpy.ndarray\n",
    "        Array to store covariance values between index and all lat/lon \n",
    "        grid points.   \n",
    "    self._stat: str\n",
    "        Specifies whether the anomalies are either mean height or bandpassed\n",
    "        variance.\n",
    "    self._method: str\n",
    "        Specifies whether to use Pearson product-moment correlation or\n",
    "        Spearman rank correlation.\n",
    "    self._period: str\n",
    "        Indicates whether the input data should be processed seasonally or \n",
    "        yearly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, anoms, indices, stat, method, period, path=None):\n",
    "        \"\"\"\n",
    "        Creates correlation and covariance arrays and saves to NetCDF4 files.\n",
    "\n",
    "        Sets object attributes and creates correlation and covariance array \n",
    "        attributes as nested dictionaries. Calculates covariance and \n",
    "        correlation between all indices contained with indices argument and\n",
    "        anomalies at every latitude/longitude grid point.\n",
    "        \n",
    "        Creates new directories for organising output files according to \n",
    "        correlation or covariance and period. Correlation and covariance \n",
    "        arrays are then saved as NetCDF4 files, to the appropriate directory. \n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        anoms: xarray.Dataset\n",
    "            Dataset containing all anomalies, with dimensions \"latitude\", \n",
    "            \"longitude\" and \"time.\n",
    "        indices: Indices object\n",
    "            Possess Indices._index_dict attribute required for calculating \n",
    "            correlations and covariance.\n",
    "        stat: str\n",
    "            Specifies whether the anomalies are either mean height or \n",
    "            bandpassed variance.\n",
    "        method: str\n",
    "            Specifies whether to use Pearson product-moment correlation or\n",
    "            Spearman rank correlation.\n",
    "        period: str\n",
    "            Indicates whether the input data should be processed seasonally\n",
    "            or yearly.\n",
    "        path: str\n",
    "            Root directory.\n",
    "        \"\"\"\n",
    "\n",
    "        self._path = path\n",
    "        self._anoms = anoms\n",
    "        self._index_dict = indices._index_dict\n",
    "        self._stat = stat\n",
    "        self._method = method\n",
    "        self._period = period\n",
    "\n",
    "        if self._path == None or self._path == \"\":\n",
    "            raise Exception(\"No path given, no figures created.\")\n",
    "\n",
    "        self._corr_arrays = self.create_corr_cov_dict()\n",
    "        self._cov_arrays = self.create_corr_cov_dict()\n",
    "\n",
    "        self.populate_corr_cov_matrices()\n",
    "      \n",
    "\n",
    "    def populate_corr_cov_matrices(self):\n",
    "        \"\"\"\n",
    "        Populates covariance and correlation dictionaries.\n",
    "\n",
    "        Handles seasonal and yearly time series. This function loops through each key\n",
    "        and sub-key in the self._index_dict attribute. The anomalies are filtered \n",
    "        according to the times indexes -- the second item in the index tuple. The \n",
    "        index series is then reformatted into a dataset and aligned with the\n",
    "        filtered anomalies dataset. These are passed to the method that calculates\n",
    "        correlation/covariance matrices, which are then assigned to the \n",
    "        key/sub-key of self._corr_arrays/self._cov_arrays corresponding to the \n",
    "        equivalent key/sub-key of self._index_dict.\n",
    "\n",
    "        For example, if self._period is \"seasonal\", the loop will go through the \n",
    "        \"DJF\" key of the self._index_dict, then \"DMI\" sub-key. Once calculated,\n",
    "        the correlation array will be assigned to self._corr_arrays[\"DJF\"][\"DMI\"].\n",
    "\n",
    "        Finally, self._corr_arrays and self._cov_arrays are passed to the method\n",
    "        that writes NetCDF files.\n",
    "        \"\"\"\n",
    "\n",
    "        if self._period == 'seasonal':\n",
    "            for season,indices in self._index_dict.items():\n",
    "                for index_name,index_tuple in indices.items():\n",
    "                    # Separate tuple of index values and time indices.\n",
    "                    index_times = index_tuple[1]\n",
    "                    index_values = index_tuple[0]\n",
    "                    # Remove values for incomplete seasons, i.e. first month of first \n",
    "                    # summer and first two months of final summer in anomalies dataset.\n",
    "                    if season == 'DJF' and self._period == 'seasonal':\n",
    "                        index_times = index_times[2:-1]\n",
    "                        index_values = index_values[2:-1]\n",
    "                    anoms_filtered = self._anoms.isel(time=index_times)\n",
    "                    \n",
    "                    # Create index dataset object.                     \n",
    "                    index_ds = self.create_indices_dataset(\n",
    "                        anoms_filtered,\n",
    "                        index_values, \n",
    "                        index_name\n",
    "                    )\n",
    "                    # Calculate corr & cov arrays for this season and index.\n",
    "                    corr_arr, cov_arr = self.calculate_corr_cov_matrices(\n",
    "                        anoms_filtered, index_ds, index_name\n",
    "                    )\n",
    "                    self._corr_arrays[season][index_name] = corr_arr\n",
    "                    self._cov_arrays[season][index_name] = cov_arr\n",
    "        else:\n",
    "            for index_name, index_tuple in self._index_dict.items():\n",
    "                # Separate tuple of index values and time indices.\n",
    "                if \"zw3\" in index_name:\n",
    "                    index_times = index_tuple[1]\n",
    "                    index_values = index_tuple[0]\n",
    "                    anoms_filtered = self._anoms.isel(time=index_times)\n",
    "                else:\n",
    "                    index_values = index_tuple[0]\n",
    "                    anoms_filtered = self._anoms\n",
    "                # Create index dataset object.\n",
    "                index_ds = self.create_indices_dataset(\n",
    "                        anoms_filtered,\n",
    "                        index_values, \n",
    "                        index_name\n",
    "                    )\n",
    "                # Calculate corr & cov arrays for this index.\n",
    "                corr_arr, cov_arr = self.calculate_corr_cov_matrices(\n",
    "                    anoms_filtered, index_ds, index_name\n",
    "                )\n",
    "                self._corr_arrays[index_name] = corr_arr\n",
    "                self._cov_arrays[index_name] = cov_arr\n",
    "\n",
    "        self._anoms.close()\n",
    "        if self._path != None:\n",
    "            self.write_to_netcdf(self._corr_arrays, 'corr')\n",
    "            self.write_to_netcdf(self._cov_arrays, 'cov')\n",
    "\n",
    "    \n",
    "    def create_corr_cov_dict(self):\n",
    "        \"\"\"\n",
    "        Creates nested dictionary with same structure as self._index_dict.\n",
    "\n",
    "        Creates a nested dictionary with keys corresponding to an index name. \n",
    "        If self._period is \"seasonal\", the first order keys will be named \n",
    "        according to the season, and a second order of sub keys will contain the\n",
    "        index name, i.e. the same structure as self._index_dict. The returned \n",
    "        dictionary is used to store data for correlation and covariance values \n",
    "        for the entire lat/lon grid.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arrays: dict\n",
    "            Dictionary with the same structure as index_dict. Each key is assigned\n",
    "            a None type as a placeholder.\n",
    "        \"\"\"\n",
    "        arrays = {}\n",
    "\n",
    "        for key in self._index_dict.keys():\n",
    "            if self._period == 'seasonal':\n",
    "                for subkey in self._index_dict[key].keys():\n",
    "                    if key not in arrays:\n",
    "                        arrays[key] = {}\n",
    "                    arrays[key][subkey] = None\n",
    "            else:\n",
    "                arrays[key] = None\n",
    "        \n",
    "        return arrays\n",
    "\n",
    "    \n",
    "    def create_indices_dataset(self, anoms, index_values, index_name):\n",
    "        \"\"\"\n",
    "        Returns index as Dataset type with additional lat & lon dimensions.\n",
    "\n",
    "        Inputted index as an array possesses only \"time\" dimension, however,\n",
    "        in order to use xarray's native corr and cov methods, the index \n",
    "        must have the same dimensions as the anomalies dataset. This \n",
    "        function takes the index time series array and forms a numpy array \n",
    "        of equivalent dimensions i.e. 3D with latitude, longitude and time.\n",
    "        The newly formed array contains a repeat of the time series at every\n",
    "        longitude, latitude grid point.\n",
    "        \n",
    "        The numpy array is converted into an xarray.Dataset object using the \n",
    "        anoms coordinates for consistency between the two datasets.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        anoms: xarray.Dataset\n",
    "            Dataset containing the filtered anomalies. Used for consistency \n",
    "            of coordinate dimensions with the new index dataset.\n",
    "        index_values: numpy.ndarray\n",
    "            Array containing the index time series.\n",
    "        index_name: str\n",
    "            Name of the index, used to assign variable name for new index\n",
    "            dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ds: xarray.Dataset\n",
    "            Index dataset with dimensions along latitude, longitude and time.\n",
    "        \"\"\"\n",
    "        lon = anoms.lon\n",
    "        lat = anoms.lat\n",
    "        time = len(index_values)\n",
    "        n = lon.size * lat.size\n",
    "\n",
    "        # Create 3D array of repeated time series\n",
    "        index_flattened = np.repeat(index_values[None, :], n, axis=0)\n",
    "        index_data = index_flattened.reshape((lon.size, lat.size, time))\n",
    "\n",
    "        # Create index dataset.\n",
    "        ds = xr.Dataset(\n",
    "                data_vars={\n",
    "                    index_name:(('lon', 'lat', 'time'), index_data)\n",
    "                    },\n",
    "                coords={\n",
    "                    'lon':lon,\n",
    "                    'lat':lat, \n",
    "                    'time':anoms.time[:time]\n",
    "                }\n",
    "            )\n",
    "        return ds\n",
    "\n",
    "    \n",
    "    def calculate_corr_cov_matrices(self, anoms, index_ds, index_name):\n",
    "        \"\"\"\n",
    "        Returns covariance and correlation matrices of two input datasets.\n",
    "\n",
    "        Filtered anomalies and index datasets are converted to DataArray \n",
    "        objects so as to use the xarray native methods corr and cov. The \n",
    "        method for calculating correlation and covariance is determined by\n",
    "        the self._method attribute.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        anoms: xarray.Dataset\n",
    "            Dataset containing the filtered anomalies of mean or variance\n",
    "            fields.\n",
    "        index_ds: xarray.Dataset\n",
    "            Dataset containg the 3D index with latitude and longitude \n",
    "            dimensions.\n",
    "        index_name: str\n",
    "            Name of index in the index_ds, used for converting the Dataset\n",
    "            into a xarray.DataArray object.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        corr_matrix: xarray.DataArray\n",
    "            Matrix containing pearson or spearman correlation values \n",
    "            between index and anomalies time series at all lon/lat grid\n",
    "            points.\n",
    "        cov_matrix: xarray.DataArray\n",
    "            Matrix containing pearson or spearman covariance values \n",
    "            between index and anomalies time series at all lon/lat grid\n",
    "            points.\n",
    "        \"\"\"\n",
    "        anoms_arr = anoms.z\n",
    "        index_arr = index_ds[index_name]\n",
    "        anoms_arr, index_arr = xr.align(anoms_arr, index_arr)\n",
    "\n",
    "        if self._method == 'pearson':\n",
    "            corr_matrix = xr.corr(anoms_arr, index_arr, dim='time')\n",
    "            cov_matrix = xr.cov(anoms_arr, index_arr, dim='time')\n",
    "        elif self._method == 'rank':\n",
    "            # Rank DataArray objects before passing to corr and cov methods.\n",
    "            ranked_anoms = anoms_arr.rank(dim='time')\n",
    "            ranked_index = index_arr.rank(dim='time')\n",
    "            corr_matrix = xr.corr(ranked_anoms, ranked_index, dim='time')\n",
    "            cov_matrix = xr.cov(ranked_anoms, ranked_index, dim='time')\n",
    "\n",
    "        return corr_matrix, cov_matrix\n",
    "\n",
    "\n",
    "    def write_to_netcdf(self, arrays: dict, var='corr'):\n",
    "        \"\"\"\n",
    "        Writes NetCDF file with dimensions at specified path location.\n",
    "\n",
    "        Creates parent directories if required. Loops through every key\n",
    "        & sub-key and writes each as a separate NetCDF file. Ensures\n",
    "        that all output files having ordered dimensions: (\"lat\", \"lon\").\n",
    "        This is for consistency in creating figures.\n",
    "        \"\"\"\n",
    "        self._opath = self._path / var / self._period\n",
    "        self._opath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Handle seasonal data.\n",
    "        if self._period == 'seasonal':\n",
    "            for season_name,indices_dict in arrays.items():\n",
    "                for index_name,index_da in indices_dict.items():\n",
    "                    ds = index_da.to_dataset(name=var)\n",
    "                    ds = ds.transpose(\"lat\", \"lon\")\n",
    "                    filename = season_name + '_' + self._stat + '_' \\\n",
    "                        + index_name + '_' + self._method + '_' \\\n",
    "                        + var +  '.nc'\n",
    "                    ds.to_netcdf(self._opath / filename)\n",
    "                    ds.close()\n",
    "        else:\n",
    "            for index_name,index_da in arrays.items():\n",
    "                ds = index_da.to_dataset(name=var)\n",
    "                ds = ds.transpose(\"lat\", \"lon\")\n",
    "                filename = self._stat + '_' \\\n",
    "                    + index_name + '_' + self._method + '_' \\\n",
    "                    + var +  '.nc'\n",
    "                ds.to_netcdf(self._opath / filename)\n",
    "                ds.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = Path(\"G:\\\\Isaac\\\\Documents\\\\msc-research\\\\data\\\\ERA5\\\\daily_data\\\\\")\n",
    "    index_path = Path(\"G:\\\\Isaac\\\\Documents\\\\msc-research\\\\data\\\\indices\\\\\")\n",
    "\n",
    "    var_file = \"era5_h500_daily_1979_2021_1deg_deseasonalised_bandpass_20S_mon_var_anoms.nc\"\n",
    "    mean_file = \"era5_h500_daily_1979_2021_1deg_deseasonalised_20S_mon_anoms.nc\"\n",
    "\n",
    "    variance_anoms = xr.open_dataset(path / var_file)\n",
    "    mean_anoms = xr.open_dataset(path / mean_file)\n",
    "    index_files = list(index_path.glob(\"*.nc\"))\n",
    "\n",
    "    # Default options, control outputs here.\n",
    "    period = 'seasonal'\n",
    "    zw3_bins=\"60_deg\"\n",
    "    variable_names = ['zw3index_magnitude',]#'sam', 'SOI', 'DMI', ]\n",
    "\n",
    "    indices = Indices(index_files, variable_names, period, zw3_bins)\n",
    "\n",
    "    anoms = [(variance_anoms, 'variance'), (mean_anoms, 'mean')]\n",
    "    methods = ['rank', 'pearson',]\n",
    "\n",
    "    for anom in anoms:\n",
    "        for method in methods:\n",
    "            inst = CorrCovMaps(\n",
    "                    anom[0], \n",
    "                    indices, \n",
    "                    stat=anom[1],\n",
    "                    method=method, \n",
    "                    period=period,\n",
    "                    path=None\n",
    "                    )\n",
    "    \n",
    "    # Currently loops through every file found in the directory,\n",
    "    # not just the ones created in the current iteration.\n",
    "    corr_maps = CreateMaps(inst._path, 'corr', inst._period)\n",
    "    cov_maps = CreateMaps(inst._path, 'cov', inst._period)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

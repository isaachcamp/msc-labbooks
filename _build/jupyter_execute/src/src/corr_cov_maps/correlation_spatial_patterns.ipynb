{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Spatial Patterns\n",
    "\n",
    "This notebook calculates the correlation between indices time series and anomaly time series, variance and mean height, at each longitude/latitude grid point. Methods used are both Pearson and Spearman rank correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from load_indices import Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrCovMaps():\n",
    "    def __init__(self, anoms, indices, stat, method, period, path=Path(\".\")):\n",
    "        \"\"\" \n",
    "        Attributes\n",
    "        ----------\n",
    "        self._anoms: xarray.Dataset\n",
    "            Dataset containing time series for all lat/lon grid points.\n",
    "        self._index_dict: dict\n",
    "            Dictionary containing arrays of all normalised indices' time series.\n",
    "        self._coords_array: numpy.ndarray\n",
    "            2D array containing all lat/lon coordinate pairs.\n",
    "        self._correlation_arrays: numpy.ndarray\n",
    "            Array to store correlation values between all indices and all lat/lon \n",
    "            grid points.\n",
    "        self._covariance_arrays: numpy.ndarray\n",
    "            Array to store covariance values between all indices and all lat/lon \n",
    "            grid points.   \n",
    "        self._stat: str\n",
    "            Specifies whether the anomalies are either mean height or bandpassed\n",
    "            variance.\n",
    "        self._method: str\n",
    "            Specifies whether to use Pearson product-moment correlation or\n",
    "            Spearman rank correlation.\n",
    "        self._period: boolean\n",
    "            Indicates whether the input data should be processed seasonally, \n",
    "            rolling three month seasons or yearly.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._path = path\n",
    "        self._anoms = anoms\n",
    "        self._index_dict = indices._index_dict\n",
    "        self._stat = stat\n",
    "        self._method = method\n",
    "        self._period = period\n",
    "\n",
    "        self._correlation_arrays = self.create_corr_cov_dict()\n",
    "        self._covariance_arrays = self.create_corr_cov_dict()\n",
    "\n",
    "        self.populate_corr_cov_matrices()\n",
    "      \n",
    "\n",
    "    def populate_corr_cov_matrices(self):\n",
    "        \"\"\"\n",
    "        This function calls the correct function to calculate correlation/covariance\n",
    "        depending on whether seasonal data is being used. \n",
    "        \"\"\"\n",
    "\n",
    "        if self._period == 'seasonal' or self._period == 'rolling_seasonal':\n",
    "            for season,variables in self._index_dict.items():\n",
    "                for variable_name,variable_values in variables.items():\n",
    "                    # Separate tuple of index values and time indices.\n",
    "                    times = variable_values[1]\n",
    "                    index_values = variable_values[0]\n",
    "                    # Remove values for incomplete seasons, i.e. first month of first \n",
    "                    # summer and first two months of final summer in anomalies dataset.\n",
    "                    if season == 'DJF' and self._period == 'seasonal':\n",
    "                        times = times[2:-1]\n",
    "                        index_values = index_values[2:-1]\n",
    "                    anoms_filtered = self._anoms.isel(time=times)\n",
    "                    index_ds = self.create_indices_dataset(\n",
    "                        anoms_filtered,\n",
    "                        index_values, \n",
    "                        variable_name\n",
    "                    )\n",
    "                    correlation_array, covariance_array = self.calculate_corr_cov_matrices(\n",
    "                        anoms_filtered, index_ds, variable_name\n",
    "                    )\n",
    "                    self._correlation_arrays[season][variable_name] = correlation_array\n",
    "                    self._covariance_arrays[season][variable_name] = covariance_array\n",
    "        else:\n",
    "            for variable_name, variable_values in self._index_dict.items():\n",
    "                if \"zw3\" in variable_name:\n",
    "                    times = variable_values[1]\n",
    "                    index_values = variable_values[0]\n",
    "                    anoms_filtered = self._anoms.isel(time=times)\n",
    "                else:\n",
    "                    index_values = variable_values\n",
    "                    anoms_filtered = self._anoms\n",
    "                index_ds = self.create_indices_dataset(\n",
    "                        anoms_filtered,\n",
    "                        index_values, \n",
    "                        variable_name\n",
    "                    )\n",
    "                corr_arr, cov_arr = self.calculate_corr_cov_matrices(\n",
    "                    anoms_filtered, index_ds, variable_name\n",
    "                )\n",
    "                self._correlation_arrays[variable_name] = corr_arr\n",
    "                self._covariance_arrays[variable_name] = cov_arr\n",
    "\n",
    "        self._anoms.close()\n",
    "        if self._path != None:\n",
    "            self.write_to_netcdf(self._correlation_arrays, 'corr')\n",
    "            self.write_to_netcdf(self._covariance_arrays, 'cov')\n",
    "\n",
    "    \n",
    "    def create_corr_cov_dict(self):\n",
    "        \"\"\"\n",
    "        Creates a dictionary of zero arrays with keys corresponding to index name and, \n",
    "        if seasonal is True, seasons. The dictionary will have the same structure as \n",
    "        index_dict. correlation_arrays will be used to store data for correlation\n",
    "        values at each lon/lat point.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arrays: dict\n",
    "            Dictionary with the same structure as index_dict. Each key has a \n",
    "            numpy.ndarray of zeroes with identical longitude/latitude dimensions\n",
    "            to the input file grid.\n",
    "        \"\"\"\n",
    "\n",
    "        arrays = {}\n",
    "\n",
    "        for key in self._index_dict.keys():\n",
    "            if self._period == 'seasonal' or self._period == 'rolling_seasonal':\n",
    "                for subkey in self._index_dict[key].keys():\n",
    "                    if key not in arrays:\n",
    "                        arrays[key] = {}\n",
    "                    arrays[key][subkey] = None\n",
    "            else:\n",
    "                arrays[key] = None\n",
    "\n",
    "        return arrays\n",
    "\n",
    "    \n",
    "    def create_indices_dataset(self, anoms, index, variable_name):\n",
    "        lon = anoms.lon\n",
    "        lat = anoms.lat\n",
    "        time = len(index)\n",
    "        n = lon.size * lat.size\n",
    "\n",
    "        index_flattened = np.repeat(index[None, :], n, axis=0)\n",
    "        index_data = index_flattened.reshape((lon.size, lat.size, time))\n",
    "\n",
    "        ds = xr.Dataset(\n",
    "                data_vars={\n",
    "                    variable_name:(('lon', 'lat', 'time'), index_data)\n",
    "                    },\n",
    "                coords={\n",
    "                    'lat':lat, \n",
    "                    'lon':lon,\n",
    "                    'time':anoms.time[:time]\n",
    "                }\n",
    "            )\n",
    "        return ds\n",
    "\n",
    "    \n",
    "    def calculate_corr_cov_matrices(self, anoms, index_ds, variable_name):\n",
    "        anoms_arr = anoms.z\n",
    "        index_arr = index_ds[variable_name]\n",
    "        anoms_arr, index_arr = xr.align(anoms_arr, index_arr)\n",
    "\n",
    "        if self._method == 'pearson':\n",
    "            corr_matrix = xr.corr(anoms_arr, index_arr, dim='time')\n",
    "        elif self._method == 'rank':\n",
    "            ranked_anoms = anoms_arr.rank(dim='time')\n",
    "            ranked_index = index_arr.rank(dim='time')\n",
    "            corr_matrix = xr.corr(ranked_anoms, ranked_index, dim='time')\n",
    "        \n",
    "        cov_matrix = xr.cov(anoms_arr, index_arr, dim='time')\n",
    "        \n",
    "        return corr_matrix, cov_matrix\n",
    "\n",
    "\n",
    "    def write_to_netcdf(self, arrays: dict, var='corr'):\n",
    "        \"\"\"\n",
    "        Writes NetCDF file with dimensions at specified path location, creates parent \n",
    "        directories if required. \n",
    "        \"\"\"\n",
    "        corr_path = self._path / var / self._period\n",
    "        corr_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Handle seasonal data.\n",
    "        if self._period == 'seasonal' or self._period == 'rolling_seasonal':\n",
    "            for season_name,variables_dict in arrays.items():\n",
    "                for variable_name,variable_values in variables_dict.items():\n",
    "                    ds = variable_values.to_dataset(name=var)\n",
    "                    filename = season_name + '_' + self._stat + '_' \\\n",
    "                        + variable_name + '_' + self._method + '_' \\\n",
    "                        + var +  '.nc'\n",
    "                    ds.to_netcdf(corr_path / filename)\n",
    "                    ds.close()\n",
    "        else:\n",
    "            for variable_name,variable_values in arrays.items():\n",
    "                ds = variable_values.to_dataset(name=var)\n",
    "                filename = season_name + '_' + self._stat + '_' \\\n",
    "                    + variable_name + '_' + self._method + '_' \\\n",
    "                    + var +  '.nc'\n",
    "                ds.to_netcdf(corr_path / filename)\n",
    "                ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"G:\\\\Isaac\\\\Documents\\\\msc-research\\\\data\\\\ERA5\\\\daily_data\\\\\")\n",
    "index_path = Path(\"G:\\\\Isaac\\\\Documents\\\\msc-research\\\\data\\\\indices\\\\\")\n",
    "\n",
    "var_file = \"era5_h500_daily_1979_2021_1deg_deseasonalised_bandpass_20S_mon_var_anoms.nc\"\n",
    "mean_file = \"era5_h500_daily_1979_2021_1deg_deseasonalised_20S_mon_anoms.nc\"\n",
    "index_files = list(index_path.glob(\"*.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zw3_-30_0 in JJA has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-30_0 in MAM has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-90_-60 in SON has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_60_90 in JJA has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_0_30 in DJF has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_0_30 in MAM has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_0_30 in SON has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_90_120 in MAM has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-120_-90 in DJF has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-120_-90 in JJA has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-120_-90 in SON has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_30_60 in JJA has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-150_-120 in JJA has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-150_-120 in MAM has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_150_180 in DJF has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_150_180 in MAM has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_150_180 in SON has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-180_-150 in DJF has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-180_-150 in JJA has fewer than 10 data. Sample size too small: it won't be correlated.\n",
      "zw3_-60_-30 in DJF has fewer than 10 data. Sample size too small: it won't be correlated.\n"
     ]
    }
   ],
   "source": [
    "period = 'seasonal'\n",
    "\n",
    "variance_anoms = xr.open_dataset(path / var_file)\n",
    "mean_anoms = xr.open_dataset(path / mean_file)\n",
    "\n",
    "variable_names = ['sam', 'DMI', 'SOI', 'zw3index_magnitude']\n",
    "indices = Indices(index_files, variable_names, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = [(variance_anoms, 'variance'), (mean_anoms, 'mean')]\n",
    "methods = ['pearson', 'rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m anom \u001b[38;5;129;01min\u001b[39;00m anoms:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[1;32m----> 3\u001b[0m         \u001b[43mCorrCovMaps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43manom\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manom\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mCorrCovMaps.__init__\u001b[1;34m(self, anoms, indices, stat, method, period, path)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correlation_arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_corr_cov_dict()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_covariance_arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_corr_cov_dict()\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_corr_cov_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mCorrCovMaps.populate_corr_cov_matrices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m anoms_filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_anoms\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39mtimes)\n\u001b[0;32m     60\u001b[0m index_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_indices_dataset(\n\u001b[0;32m     61\u001b[0m     anoms_filtered,\n\u001b[0;32m     62\u001b[0m     index_values, \n\u001b[0;32m     63\u001b[0m     variable_name\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m correlation_array, covariance_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_corr_cov_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43manoms_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_name\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correlation_arrays[season][variable_name] \u001b[38;5;241m=\u001b[39m correlation_array\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_covariance_arrays[season][variable_name] \u001b[38;5;241m=\u001b[39m covariance_array\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mCorrCovMaps.calculate_corr_cov_matrices\u001b[1;34m(self, anoms, index_ds, variable_name)\u001b[0m\n\u001b[0;32m    150\u001b[0m anoms_arr, index_arr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39malign(anoms_arr, index_arr)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 153\u001b[0m     corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43manoms_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    155\u001b[0m     ranked_anoms \u001b[38;5;241m=\u001b[39m anoms_arr\u001b[38;5;241m.\u001b[39mrank(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\computation.py:1330\u001b[0m, in \u001b[0;36mcorr\u001b[1;34m(da_a, da_b, dim)\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m [da_a, da_b]):\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly xr.DataArray is supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat([\u001b[38;5;28mtype\u001b[39m(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m [da_a, da_b]])\n\u001b[0;32m   1328\u001b[0m     )\n\u001b[1;32m-> 1330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cov_corr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mda_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcorr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\computation.py:1342\u001b[0m, in \u001b[0;36m_cov_corr\u001b[1;34m(da_a, da_b, dim, ddof, method)\u001b[0m\n\u001b[0;32m   1339\u001b[0m da_a, da_b \u001b[38;5;241m=\u001b[39m align(da_a, da_b, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;66;03m# 2. Ignore the nans\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m valid_values \u001b[38;5;241m=\u001b[39m da_a\u001b[38;5;241m.\u001b[39mnotnull() \u001b[38;5;241m&\u001b[39m \u001b[43mda_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotnull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1343\u001b[0m da_a \u001b[38;5;241m=\u001b[39m da_a\u001b[38;5;241m.\u001b[39mwhere(valid_values)\n\u001b[0;32m   1344\u001b[0m da_b \u001b[38;5;241m=\u001b[39m da_b\u001b[38;5;241m.\u001b[39mwhere(valid_values)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\common.py:1373\u001b[0m, in \u001b[0;36mDataWithCoords.notnull\u001b[1;34m(self, keep_attrs)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_attrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1371\u001b[0m     keep_attrs \u001b[38;5;241m=\u001b[39m _get_keep_attrs(default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_ufunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotnull\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallowed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\computation.py:1159\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[1;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;66;03m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_dataarray_vfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables_vfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m# feed Variables directly through apply_variable_ufunc\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, Variable) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\computation.py:286\u001b[0m, in \u001b[0;36mapply_dataarray_vfunc\u001b[1;34m(func, signature, join, exclude_dims, keep_attrs, *args)\u001b[0m\n\u001b[0;32m    281\u001b[0m result_coords \u001b[38;5;241m=\u001b[39m build_output_coords(\n\u001b[0;32m    282\u001b[0m     args, signature, exclude_dims, combine_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 286\u001b[0m result_var \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    289\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    290\u001b[0m         DataArray(variable, coords, name\u001b[38;5;241m=\u001b[39mname, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m variable, coords \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result_var, result_coords)\n\u001b[0;32m    292\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\computation.py:727\u001b[0m, in \u001b[0;36mapply_variable_ufunc\u001b[1;34m(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorize:\n\u001b[0;32m    723\u001b[0m         func \u001b[38;5;241m=\u001b[39m _vectorize(\n\u001b[0;32m    724\u001b[0m             func, signature, output_dtypes\u001b[38;5;241m=\u001b[39moutput_dtypes, exclude_dims\u001b[38;5;241m=\u001b[39mexclude_dims\n\u001b[0;32m    725\u001b[0m         )\n\u001b[1;32m--> 727\u001b[0m result_data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    730\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m (result_data,)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\duck_array_ops.py:125\u001b[0m, in \u001b[0;36mnotnull\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotnull\u001b[39m(data):\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m~\u001b[39m\u001b[43misnull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\msc-research\\lib\\site-packages\\xarray\\core\\duck_array_ops.py:108\u001b[0m, in \u001b[0;36misnull\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m isnat(data)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(scalar_type, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# float types use NaN for null\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(scalar_type, (np\u001b[38;5;241m.\u001b[39mbool_, np\u001b[38;5;241m.\u001b[39minteger, np\u001b[38;5;241m.\u001b[39mcharacter, np\u001b[38;5;241m.\u001b[39mvoid)):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# these types cannot represent missing values\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m zeros_like(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for anom in anoms:\n",
    "    for method in methods:\n",
    "        CorrCovMaps(\n",
    "            anom[0], indices, stat=anom[1],\n",
    "            method=method, period=period,\n",
    "            path=path\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation & Covariance Maps\n",
    "\n",
    "This notebook calculates the correlation & covariance between indices time series and anomalies time series, for bandpassed variance and mean height fields, at each longitude/latitude grid point. Methods used are both Pearson product-moment and Spearman rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_indices\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Indices\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcreate_cartopy_maps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CreateMaps\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorrCovMaps\u001b[39;00m():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'load_indices'"
     ]
    }
   ],
   "source": [
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from load_indices import Indices\n",
    "from create_cartopy_maps import CreateMaps\n",
    "\n",
    "\n",
    "class CorrCovMaps():\n",
    "    def __init__(self, anoms, indices, stat, method, period, path=Path(\".\")):\n",
    "        \"\"\" \n",
    "        Attributes\n",
    "        ----------\n",
    "        self._anoms: xarray.Dataset\n",
    "            Dataset containing time series for all lat/lon grid points.\n",
    "        self._index_dict: dict\n",
    "            Dictionary containing arrays of all normalised indices' time series.\n",
    "        self._coords_array: numpy.ndarray\n",
    "            2D array containing all lat/lon coordinate pairs.\n",
    "        self._correlation_arrays: numpy.ndarray\n",
    "            Array to store correlation values between all indices and all lat/lon \n",
    "            grid points.\n",
    "        self._covariance_arrays: numpy.ndarray\n",
    "            Array to store covariance values between all indices and all lat/lon \n",
    "            grid points.   \n",
    "        self._stat: str\n",
    "            Specifies whether the anomalies are either mean height or bandpassed\n",
    "            variance.\n",
    "        self._method: str\n",
    "            Specifies whether to use Pearson product-moment correlation or\n",
    "            Spearman rank correlation.\n",
    "        self._period: boolean\n",
    "            Indicates whether the input data should be processed seasonally, \n",
    "            rolling three month seasons or yearly.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._path = path\n",
    "        self._anoms = anoms\n",
    "        self._index_dict = indices._index_dict\n",
    "        self._stat = stat\n",
    "        self._method = method\n",
    "        self._period = period\n",
    "\n",
    "        self._correlation_arrays = self.create_corr_cov_dict()\n",
    "        self._covariance_arrays = self.create_corr_cov_dict()\n",
    "\n",
    "        self.populate_corr_cov_matrices()\n",
    "      \n",
    "\n",
    "    def populate_corr_cov_matrices(self):\n",
    "        \"\"\"\n",
    "        This function calls the correct function to calculate correlation/covariance\n",
    "        depending on whether seasonal data is being used. \n",
    "        \"\"\"\n",
    "\n",
    "        if self._period == 'seasonal' or self._period == 'rolling_seasonal':\n",
    "            for season,variables in self._index_dict.items():\n",
    "                for variable_name,variable_values in variables.items():\n",
    "                    # Separate tuple of index values and time indices.\n",
    "                    times = variable_values[1]\n",
    "                    index_values = variable_values[0]\n",
    "                    # Remove values for incomplete seasons, i.e. first month of first \n",
    "                    # summer and first two months of final summer in anomalies dataset.\n",
    "                    if season == 'DJF' and self._period == 'seasonal':\n",
    "                        times = times[2:-1]\n",
    "                        index_values = index_values[2:-1]\n",
    "                    anoms_filtered = self._anoms.isel(time=times)                        \n",
    "                    index_ds = self.create_indices_dataset(\n",
    "                        anoms_filtered,\n",
    "                        index_values, \n",
    "                        variable_name\n",
    "                    )\n",
    "                    correlation_array, covariance_array = self.calculate_corr_cov_matrices(\n",
    "                        anoms_filtered, index_ds, variable_name\n",
    "                    )\n",
    "                    self._correlation_arrays[season][variable_name] = correlation_array\n",
    "                    self._covariance_arrays[season][variable_name] = covariance_array\n",
    "        else:\n",
    "            for variable_name, variable_values in self._index_dict.items():\n",
    "                if \"zw3\" in variable_name:\n",
    "                    times = variable_values[1]\n",
    "                    index_values = variable_values[0]\n",
    "                    anoms_filtered = self._anoms.isel(time=times)\n",
    "                else:\n",
    "                    index_values = variable_values\n",
    "                    anoms_filtered = self._anoms\n",
    "                index_ds = self.create_indices_dataset(\n",
    "                        anoms_filtered,\n",
    "                        index_values, \n",
    "                        variable_name\n",
    "                    )\n",
    "                corr_arr, cov_arr = self.calculate_corr_cov_matrices(\n",
    "                    anoms_filtered, index_ds, variable_name\n",
    "                )\n",
    "                self._correlation_arrays[variable_name] = corr_arr\n",
    "                self._covariance_arrays[variable_name] = cov_arr\n",
    "\n",
    "        self._anoms.close()\n",
    "        if self._path != None:\n",
    "            self.write_to_netcdf(self._correlation_arrays, 'corr')\n",
    "            self.write_to_netcdf(self._covariance_arrays, 'cov')\n",
    "\n",
    "    \n",
    "    def create_corr_cov_dict(self):\n",
    "        \"\"\"\n",
    "        Creates a dictionary of zero arrays with keys corresponding to index name and, \n",
    "        if seasonal is True, seasons. The dictionary will have the same structure as \n",
    "        index_dict. correlation_arrays will be used to store data for correlation\n",
    "        values at each lon/lat point.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arrays: dict\n",
    "            Dictionary with the same structure as index_dict. Each key has a \n",
    "            numpy.ndarray of zeroes with identical longitude/latitude dimensions\n",
    "            to the input file grid.\n",
    "        \"\"\"\n",
    "\n",
    "        arrays = {}\n",
    "\n",
    "        for key in self._index_dict.keys():\n",
    "            if self._period == 'seasonal' or self._period == 'rolling_seasonal':\n",
    "                for subkey in self._index_dict[key].keys():\n",
    "                    if key not in arrays:\n",
    "                        arrays[key] = {}\n",
    "                    arrays[key][subkey] = None\n",
    "            else:\n",
    "                arrays[key] = None\n",
    "\n",
    "        return arrays\n",
    "\n",
    "    \n",
    "    def create_indices_dataset(self, anoms, index, variable_name):\n",
    "        lon = anoms.lon\n",
    "        lat = anoms.lat\n",
    "        time = len(index)\n",
    "        n = lon.size * lat.size\n",
    "\n",
    "        index_flattened = np.repeat(index[None, :], n, axis=0)\n",
    "        index_data = index_flattened.reshape((lon.size, lat.size, time))\n",
    "\n",
    "        ds = xr.Dataset(\n",
    "                data_vars={\n",
    "                    variable_name:(('lon', 'lat', 'time'), index_data)\n",
    "                    },\n",
    "                coords={\n",
    "                    'lon':lon,\n",
    "                    'lat':lat, \n",
    "                    'time':anoms.time[:time]\n",
    "                }\n",
    "            )\n",
    "        return ds\n",
    "\n",
    "    \n",
    "    def calculate_corr_cov_matrices(self, anoms, index_ds, variable_name):\n",
    "        anoms_arr = anoms.z\n",
    "        index_arr = index_ds[variable_name]\n",
    "        anoms_arr, index_arr = xr.align(anoms_arr, index_arr)\n",
    "\n",
    "        if self._method == 'pearson':\n",
    "            corr_matrix = xr.corr(anoms_arr, index_arr, dim='time')\n",
    "            cov_matrix = xr.cov(anoms_arr, index_arr, dim='time')\n",
    "        elif self._method == 'rank':\n",
    "            ranked_anoms = anoms_arr.rank(dim='time')\n",
    "            ranked_index = index_arr.rank(dim='time')\n",
    "            corr_matrix = xr.corr(ranked_anoms, ranked_index, dim='time')\n",
    "            cov_matrix = xr.cov(ranked_anoms, ranked_index, dim='time')\n",
    "        \n",
    "        \n",
    "        return corr_matrix, cov_matrix\n",
    "\n",
    "\n",
    "    def write_to_netcdf(self, arrays: dict, var='corr'):\n",
    "        \"\"\"\n",
    "        Writes NetCDF file with dimensions at specified path location, creates parent \n",
    "        directories if required. \n",
    "        \"\"\"\n",
    "        self._opath = self._path / var / self._period\n",
    "        self._opath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Handle seasonal data.\n",
    "        if self._period == 'seasonal' or self._period == 'rolling_seasonal':\n",
    "            for season_name,variables_dict in arrays.items():\n",
    "                for variable_name,variable_values in variables_dict.items():\n",
    "                    ds = variable_values.to_dataset(name=var)\n",
    "                    ds = ds.transpose(\"lat\", \"lon\")\n",
    "                    filename = season_name + '_' + self._stat + '_' \\\n",
    "                        + variable_name + '_' + self._method + '_' \\\n",
    "                        + var +  '.nc'\n",
    "                    ds.to_netcdf(self._opath / filename)\n",
    "                    ds.close()\n",
    "        else:\n",
    "            for variable_name,variable_values in arrays.items():\n",
    "                ds = variable_values.to_dataset(name=var)\n",
    "                ds = ds.transpose(\"lat\", \"lon\")\n",
    "                filename = self._stat + '_' \\\n",
    "                    + variable_name + '_' + self._method + '_' \\\n",
    "                    + var +  '.nc'\n",
    "                ds.to_netcdf(self._opath / filename)\n",
    "                ds.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = Path(\"G:\\\\Isaac\\\\Documents\\\\msc-research\\\\data\\\\ERA5\\\\daily_data\\\\\")\n",
    "    index_path = Path(\"G:\\\\Isaac\\\\Documents\\\\msc-research\\\\data\\\\indices\\\\\")\n",
    "\n",
    "    var_file = \"era5_h500_daily_1979_2021_1deg_deseasonalised_bandpass_20S_mon_var_anoms.nc\"\n",
    "    mean_file = \"era5_h500_daily_1979_2021_1deg_deseasonalised_20S_mon_anoms.nc\"\n",
    "\n",
    "    variance_anoms = xr.open_dataset(path / var_file)\n",
    "    mean_anoms = xr.open_dataset(path / mean_file)\n",
    "\n",
    "    period = 'yearly'\n",
    "    index_files = list(index_path.glob(\"*.nc\"))\n",
    "    variable_names = ['zw3index_magnitude','sam', 'SOI', 'DMI', ]\n",
    "    indices = Indices(index_files, variable_names, period)\n",
    "\n",
    "    anoms = [(variance_anoms, 'variance'), (mean_anoms, 'mean')]\n",
    "    methods = ['rank', 'pearson',]\n",
    "\n",
    "    for anom in anoms:\n",
    "        for method in methods:\n",
    "            inst = CorrCovMaps(\n",
    "                    anom[0], \n",
    "                    indices, \n",
    "                    stat=anom[1],\n",
    "                    method=method, \n",
    "                    period=period,\n",
    "                    path=path\n",
    "                    )\n",
    "    \n",
    "    corr_maps = CreateMaps(inst._path, 'corr', inst._period)\n",
    "    cov_maps = CreateMaps(inst._path, 'cov', inst._period)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}